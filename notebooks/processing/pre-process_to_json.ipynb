{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e0ec6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, RDF\n",
    "\n",
    "def ttl_corpora_tags(filename:str) -> list[dict]:\n",
    "    g = Graph()\n",
    "    g.parse(filename, format=\"turtle\")\n",
    "\n",
    "    NIF = Namespace(\"http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#\")\n",
    "    ITSRDF = Namespace(\"http://www.w3.org/2005/11/its/rdf#\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for context in g.subjects(RDF.type, NIF.Context):\n",
    "        entry = {\"corpus\": None, \"tags\": []}\n",
    "\n",
    "        for text in g.objects(context, NIF.isString):\n",
    "            entry[\"corpus\"] = str(text)\n",
    "\n",
    "        for span in g.subjects(NIF.referenceContext, context):\n",
    "            tag = {}\n",
    "\n",
    "            for anchor in g.objects(span, NIF.anchorOf):\n",
    "                tag[\"text\"] = str(anchor)\n",
    "\n",
    "            for begin in g.objects(span, NIF.beginIndex):\n",
    "                tag[\"beginIndex\"] = int(begin)\n",
    "            for end in g.objects(span, NIF.endIndex):\n",
    "                tag[\"endIndex\"] = int(end)\n",
    "\n",
    "            for ref in g.objects(span, ITSRDF.taIdentRef):\n",
    "                tag[\"uri\"] = str(ref)\n",
    "\n",
    "            if tag:\n",
    "                entry[\"tags\"].append(tag)\n",
    "\n",
    "        data.append(entry)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tsv_to_json(filename):\n",
    "    data = []\n",
    "    current_doc_corpus = \"\"\n",
    "    current_doc_tags = []\n",
    "\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "            try:\n",
    "                line = line.encode(\"latin1\").decode(\"utf-8\")\n",
    "            except Exception:\n",
    "                pass\n",
    "            if line.startswith('-DOCSTART-'):\n",
    "                if current_doc_corpus:\n",
    "                    data.append({\"corpus\":current_doc_corpus.strip(), \"tags\":current_doc_tags})\n",
    "                    current_doc_corpus = \"\"\n",
    "                    current_doc_tags = []\n",
    "                continue\n",
    "            if not line:\n",
    "                continue\n",
    "            if '\\t' in line:\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) == 4:\n",
    "                    token, mention_type, mention_string, entity = parts\n",
    "                    if mention_type == \"B\" and entity != \"--NME--\":\n",
    "                        current_doc_tags.append(\n",
    "                            {\n",
    "                                \"text\": token,\n",
    "                                \"beginIndex\": len(current_doc_corpus),\n",
    "                                \"endIndex\": len(current_doc_corpus) + len(token),\n",
    "                                \"uri\": f\"https://en.wikipedia.org/wiki/{entity}\"\n",
    "                            }\n",
    "                        )\n",
    "                    elif entity != \"--NME--\":\n",
    "                        current_doc_tags[-1]['text'] += f\" {token}\"\n",
    "                        current_doc_tags[-1]['endIndex'] = len(current_doc_corpus) + len(token)\n",
    "                    current_doc_corpus += f\"{token} \"\n",
    "            else:\n",
    "                current_doc_corpus += f\"{line} \"\n",
    "            current_doc_corpus = current_doc_corpus.replace(\" ,\",\",\").replace(\" .\",\".\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0894f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for file in [\n",
    "    \"../../data/N3/RSS-500.ttl\",\n",
    "    \"../../data/N3/Reuters-128.ttl\",\n",
    "    \"../../data/MSNBC/MSNBCt.ttl\",\n",
    "    \"../../data/OKE/evaluation-dataset-task1.ttl\"\n",
    "    ]:\n",
    "    \n",
    "    data = [x for x in ttl_corpora_tags(file) if x['corpus'] and x['tags']]\n",
    "    fname_short = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    with open(f\"../../data/jsons/{fname_short}.json\",\"w+\",encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(data,indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0bc0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [\n",
    "    \"../../data/KORE50/KORE50.tsv\"\n",
    "    ]:\n",
    "    \n",
    "    data = [x for x in tsv_to_json(file) if x['corpus'] and x['tags']]\n",
    "    fname_short = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    with open(f\"../../data/jsons/{fname_short}.json\",\"w+\",encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(data,indent=4, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Contextual-Augmentation-for-EL-using-LLMs (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
